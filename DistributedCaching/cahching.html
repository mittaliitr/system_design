<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Distributed Caching: Cleaned Full Transcript</title>
  <style>
    body {
        font-family: 'Segoe UI', Arial, sans-serif;
        background: #f8f9fa;
        color: #23272f;
        margin: 0;
        padding: 0 0 3em 0;
    }
    main {
        max-width: 900px;
        margin: 2em auto;
        background: #fff;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.07);
        padding: 2em 2.5em;
    }
    h1, h2 {
        color: #1a4d7a;
        margin-top: 1.5em;
    }
    h1 {
        text-align: center;
        margin-bottom: 0.5em;
    }
    section {
        margin-bottom: 2.5em;
    }
    ul, ol {
        margin-left: 1.5em;
    }
    .quote {
        color: #555;
        background: #f1f3f6;
        border-left: 4px solid #a2c2e2;
        padding: 0.8em 1.2em;
        margin: 1em 0;
        font-style: italic;
    }
    .subsection {
        margin-top: 1.2em;
        font-weight: bold;
        color: #2d5a88;
    }
    .table-wrap {
        overflow-x: auto;
    }
    table {
        border-collapse: collapse;
        width: 100%;
        margin: 1em 0;
    }
    th, td {
        border: 1px solid #d0d7de;
        padding: 0.6em 0.9em;
        text-align: left;
    }
    th {
        background: #e6f0fa;
    }
    .timestamp {
        color: #999;
        font-size: 0.95em;
    }
    .speaker {
        color: #1a4d7a;
        font-weight: bold;
    }
    .block {
        margin-bottom: 1.2em;
    }
  </style>
</head>
<body>
<main>
  <h1>Distributed Caching: Full Transcript (Cleaned)</h1>

  <section>
    <h2>Introduction to Distributed Caching</h2>
    <img src="/system_design/DistributedCaching/distributed_Caching.png" alt="Distributed Caching">

    <div class="block">
      <span class="timestamp">(00:00)</span> Welcome back. I've changed my camera angle, switched up my desk setup, and things are looking clean. We're getting close to the end of this systems design concepts series. Let's start talking about caching.
    </div>
    <div class="block">
      <span class="timestamp">(00:32)</span> If you remember from your operating systems class, here's what a CPU looks like: cores, layers of cache, memory, and finally disk. The point is, we have this hierarchy of cache that enables faster reads and writes, and shields some accesses to slower forms of data like memory and disk. In distributed systems, we're basically doing the same thing.
    </div>
    <div class="block">
      <span class="timestamp">(01:27)</span> Benefits of caching in distributed systems:
      <ul>
        <li>Reads and writes should be faster because you're using a faster form of storage, usually memory instead of disk.</li>
        <li>You might save a lot of network calls by not reaching out to the database every time.</li>
        <li>You can place the cache physically closer to the client, so packets travel less distance.</li>
        <li>Caching can reduce load on key components like a single database node if many clients are asking for the same data.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(02:56)</span> Drawbacks:
      <ul>
        <li>Cache misses are expensive and slow you down.</li>
        <li>Data consistency is complex. Different caches might have different values, leading to stale data.</li>
        <li>Complexity increases if you care about strong consistency.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(04:08)</span> What do we cache? Anything that's expensive to compute or load, like database results, computations done by application servers, or popular static content.
    </div>
    <div class="block">
      <span class="timestamp">(04:57)</span> Where do we store the cache?
      <ul>
        <li><b>Server-local caching:</b> Data is cached on the application servers themselves. This could be a database, message broker, application server, or coordination service.</li>
        <li>Example: If you keep checking who liked you on Tinder, it's more efficient to cache the result on the application server.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(06:21)</span> With multiple application servers, it's important to reach the same server every time for your specific cached data. Consistent hashing is used to maximize cache hits.
    </div>
    <div class="block">
      <span class="timestamp">(07:31)</span> Pros of server-local caching: fewer network calls, faster access. Cons: if the server goes down, the cache is lost; limited by the number of application servers.
    </div>
    <div class="block">
      <span class="timestamp">(08:03)</span> <b>Global caching layer:</b> A separate, scalable caching layer shared by all servers. Pros: can scale independently. Cons: cache is no longer local, more network calls, more moving parts.
    </div>
    <div class="block">
      <span class="timestamp">(09:30)</span> Caches improve latencies for reads and writes, use faster storage, and can be placed closer to the user. But cache misses are bad, and data consistency issues can arise. Next up: cache writes and eviction policies.
    </div>
  </section>

  <section>
    <h2>Distributed Cache Write Strategies</h2>
    <img src="/system_design/DistributedCaching/cache_Write.jpg" alt="Distributed cache write">

    <div class="block">
      <span class="timestamp">(00:00)</span> Quick recap: caching can make reads faster, sometimes writes too. Caching can act as a wall between the database and users, reducing load. But cache misses are expensive, and data consistency can be tough.
    </div>
    <div class="block">
      <span class="timestamp">(01:59)</span> Three ways to handle writes:
      <ol>
        <li><b>Write-Around Cache:</b> Write directly to the database, bypassing the cache. The cache is updated on the next read (either after cache expiry or manual invalidation). Pros: simple, database is the source of truth. Cons: cache misses after writes, potential for stale reads until cache is refreshed.</li>
        <li><b>Write-Through Cache:</b> Write to both the cache and the database at the same time. Ensures cache and database are kept in sync unless a failure occurs. Two-phase commit can be used for stronger consistency, but it's slow. Pros: consistent data. Cons: slower writes, complexity.</li>
        <li><b>Write-Back Cache:</b> Write to the cache first, then asynchronously write to the database (possibly in batches). Very fast writes, but risk of data loss if the cache fails before data is persisted. Consistency can be improved with distributed locks, but adds complexity and latency. Pros: very fast writes. Cons: risk of data loss, potential for stale reads, added complexity.</li>
      </ol>
    </div>
    <div class="block">
      <span class="timestamp">(10:55)</span> No clear winner: each write strategy has different use cases and tradeoffs.
    </div>
  </section>

  <section>
    <h2>Cache Eviction Policies</h2>
    <img src="/system_design/DistributedCaching/chace_Eviction_policy.jpg" alt="Distributed eviction">

    <div class="block">
      <span class="timestamp">(00:00)</span> When you have too much data in the cache, you have to get rid of some of it. The eviction policy determines what to remove.
    </div>
    <div class="block">
      <span class="timestamp">(01:56)</span> Eviction policies:
      <ul>
        <li><b>FIFO (First-In, First-Out):</b> Oldest cached item is removed first. Simple, but may evict frequently accessed data.</li>
        <li><b>LRU (Least Recently Used):</b> Removes the item that hasn't been accessed for the longest time. Implemented with a hashmap and doubly-linked list for O(1) updates. Common in practice.</li>
        <li><b>LFU (Least Frequently Used):</b> Removes the item accessed the least number of times. More complex to implement, but can better retain "hot" data.</li>
        <li><b>Random:</b> Evicts a random item. Simple, minimal metadata, but can remove useful data.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(07:10)</span> There is no single right answer for choosing an eviction policy, but some are better than others (e.g., LRU is generally better than FIFO or random).
    </div>
  </section>
  <img src="/system_design/DistributedCaching/resis_memcached.jpg" alt=redis vs memcached>

  <section>
    <h2>Redis vs. Memcached (Detailed Comparison)</h2>

    <div class="block">
      <span class="timestamp">(00:00)</span> So, Redis and Memcached are both super popular in-memory caching solutions, but they’re actually pretty different once you get into the details. Let’s break it down.
    </div>

    <div class="block">
      <b>Core Purpose and Use Case</b>
      <ul>
        <li>Memcached is your classic, no-frills, high-speed cache. It’s a simple key-value store-just strings, no fancy data types. If you need to cache database query results, HTML fragments, or session tokens, Memcached is super lightweight and easy to set up. It’s like a RAM-powered sticky note for your app <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li>Redis is more of a Swiss Army knife. It’s a cache, but also a data structure server, message broker, and even a lightweight database if you want it to be. You get strings, but also lists, sets, sorted sets, hashes, bitmaps, hyperloglogs, geospatial indexes, and more. If you want to build leaderboards, session stores, real-time analytics, or anything with more complex data, Redis is your go-to <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Data Structures</b>
      <ul>
        <li><b>Memcached:</b> Strings only. Everything is a string, so if you want to cache an object, you have to serialize it yourself. No way to update a single field in a cached object-you have to replace the whole thing <span class="timestamp">(03:25)</span>[3][6][7].</li>
        <li><b>Redis:</b> Strings, lists, sets, sorted sets, hashes, bitmaps, hyperloglogs, geospatial data. You can update just one field in a hash, push to a list, increment a counter, or run set operations-all in-memory and super fast <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Persistence</b>
      <ul>
        <li><b>Memcached:</b> Purely in-memory. If the server restarts, all data is gone. No built-in way to persist data to disk <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li><b>Redis:</b> Optional persistence. You can snapshot data to disk at intervals (RDB), or log every write operation (AOF). If you want your cache to survive restarts or act as a lightweight database, Redis has you covered <span class="timestamp">(05:13)</span>[2][3][4][5][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Threading and Performance</b>
      <ul>
        <li><b>Memcached:</b> Multi-threaded. Can use all CPU cores, so it’s great for high-concurrency, high-throughput workloads. Handles lots of simultaneous requests very efficiently <span class="timestamp">(03:43)</span>[2][3][4][6][7].</li>
        <li><b>Redis:</b> Historically single-threaded (one command at a time), but highly optimized with event-driven, non-blocking I/O. Recent versions support multi-threaded I/O for reads. Still, for pure parallelism, Memcached has the edge <span class="timestamp">(05:13)</span>[2][3][4][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Scalability and Clustering</b>
      <ul>
        <li><b>Memcached:</b> Scales horizontally by adding more nodes. Uses consistent hashing for partitioning data across nodes. No built-in replication or clustering-if a node fails, its data is lost <span class="timestamp">(03:43)</span>[2][3][4][6][7].</li>
        <li><b>Redis:</b> Supports clustering, replication, and sharding out of the box. Redis Cluster uses a fixed number of slots (partitions) distributed across nodes, with automatic failover. Also supports replicas for high availability <span class="timestamp">(05:50)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Advanced Features</b>
      <ul>
        <li><b>Memcached:</b> Keeps it simple-just caching, no extra features. LRU eviction by default, predictable memory usage via slab allocation <span class="timestamp">(04:54)</span>[3][4][7].</li>
        <li><b>Redis:</b>
          <ul>
            <li>Transactions (MULTI/EXEC)</li>
            <li>Pub/Sub messaging for real-time feeds and chat</li>
            <li>Lua scripting for custom logic</li>
            <li>Geospatial queries</li>
            <li>Bitmaps and HyperLogLogs for analytics</li>
            <li>Snapshots and append-only file for durability</li>
          </ul>
          <span class="timestamp">(06:22)</span>[2][3][4][5][6][7].
        </li>
      </ul>
    </div>

    <div class="block">
      <b>Memory Management</b>
      <ul>
        <li><b>Memcached:</b> Allocates a fixed amount of memory up front, uses slab allocation to minimize fragmentation. Predictable, but if you run out of memory, old data is evicted <span class="timestamp">(03:43)</span>[3][4][7][8].</li>
        <li><b>Redis:</b> Uses jemalloc for dynamic allocation and has a built-in defragmentation tool. Can be configured with or without a memory limit; supports multiple eviction policies <span class="timestamp">(05:13)</span>[3][4][7][8].</li>
      </ul>
    </div>

    <div class="block">
      <b>Programming Language Support</b>
      <ul>
        <li>Both Redis and Memcached have open-source clients for nearly every language: Java, Python, PHP, C, C++, C#, JavaScript, Node.js, Ruby, Go, and more <span class="timestamp">(General)</span>[2][3][4][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Typical Use Cases</b>
      <ul>
        <li><b>Memcached:</b> Simple, high-speed cache for database query results, session tokens, HTML fragments, and other string data. Great for web apps that need to cache lots of small, frequently accessed items <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li><b>Redis:</b> Session stores, leaderboards, real-time analytics, queues, pub/sub systems, geospatial lookups, and any use case that benefits from advanced data types or persistence <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Summary Table</b>
      <div class="table-wrap">
        <table>
          <tr>
            <th>Feature</th>
            <th>Redis</th>
            <th>Memcached</th>
          </tr>
          <tr>
            <td>Data Types</td>
            <td>Strings, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, geospatial</td>
            <td>Strings only</td>
          </tr>
          <tr>
            <td>Persistence</td>
            <td>Optional (RDB snapshots, AOF logs)</td>
            <td>None (RAM only)</td>
          </tr>
          <tr>
            <td>Threading</td>
            <td>Single-threaded (multi-threaded I/O in new versions)</td>
            <td>Multi-threaded</td>
          </tr>
          <tr>
            <td>Clustering</td>
            <td>Built-in clustering, replication, failover</td>
            <td>Manual sharding, no built-in replication</td>
          </tr>
          <tr>
            <td>Eviction Policy</td>
            <td>Configurable (LRU, LFU, etc.)</td>
            <td>LRU by default</td>
          </tr>
          <tr>
            <td>Transactions</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Pub/Sub</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Lua Scripting</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Geospatial</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Memory Management</td>
            <td>jemalloc, dynamic, defragmentation</td>
            <td>Slab allocation, fixed</td>
          </tr>
          <tr>
            <td>Best For</td>
            <td>Complex data, persistence, advanced features</td>
            <td>Simple, high-throughput caching</td>
          </tr>
        </table>
      </div>
    </div>

    <div class="block">
      <b>Which Should You Use?</b>
      <ul>
        <li>If you just need a blazing-fast, distributed cache for simple key-value pairs, Memcached is lightweight, easy, and efficient <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li>If you want advanced data types, persistence, clustering, or features like pub/sub and scripting, Redis is the clear winner. Redis can do everything Memcached can-and a lot more <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>
  </section>

  <section>
    <div class="container">
      <h1>Redis Deep Dive: Detailed Documentation</h1>
      <p>
        This document summarizes and expands on the key points from the transcript of a Redis deep dive session led by Stefan, an ex-Meta Senior Manager and co-founder of Hello Interview. The session is designed to provide foundational knowledge for system design interviews, focusing on Redis’s architecture, operational model, and practical use cases.
      </p>

      <h2>1. Introduction to Redis</h2>
      <ul>
        <li>
          <strong>Purpose of the Deep Dive:</strong>
          The session aims to provide depth in core technologies, specifically Redis, to help candidates succeed in system design interviews. Redis is chosen for its versatility, simplicity, and relevance across a range of system design scenarios.
        </li>
        <li>
          <strong>Why Learn Redis?</strong>
          <ul>
            <li><strong>Versatility:</strong> Used for caches, distributed locks, leaderboards, pub/sub, and even as a Kafka replacement in some cases.</li>
            <li><strong>Simplicity:</strong> The conceptual model is straightforward, making it easier to reason about performance and debug issues compared to more complex databases like PostgreSQL.</li>
          </ul>
        </li>
      </ul>

      <h2>2. Redis Architecture and Core Concepts</h2>
      <h3>Single-Threaded, In-Memory Data Structure Server</h3>
      <ul>
        <li>
          <strong>Single-Threaded:</strong>
          Redis processes one request at a time, simplifying concurrency and making operation ordering predictable. This is unusual for distributed systems but makes debugging and reasoning about performance easier.
        </li>
        <li>
          <strong>In-Memory:</strong>
          <ul>
            <li>All data is stored in RAM, enabling sub-millisecond response times for simple operations (e.g., <code>GET</code>, <code>SET</code>).</li>
            <li>Durability is not guaranteed by default; Redis can lose recent data if not configured for persistence.</li>
          </ul>
        </li>
        <li>
          <strong>Data Structure Server:</strong>
          <ul>
            <li>Redis is more than a key-value store; values can be strings, numbers, sorted sets, hashes, geospatial indexes, Bloom filters, and more.</li>
            <li>The API mirrors common data structures from computer science, allowing developers to apply their algorithms knowledge directly.</li>
          </ul>
        </li>
      </ul>

      <h2>3. Redis Operational Model</h2>
      <h3>Basic Usage</h3>
      <ul>
        <li>
          <strong>Installation and CLI:</strong>
          Redis can be installed locally and interacted with via a simple command-line interface.
        </li>
        <li>
          <strong>Wire Protocol:</strong>
          Accepts straightforward commands (e.g., <code>SET</code>, <code>GET</code>, <code>INCR</code>), each operating on a key.
        </li>
        <li>
          <strong>Command Organization:</strong>
          Commands are grouped by data type; not all commands are valid on all data types.
        </li>
      </ul>

      <h3>Persistence and Replication</h3>
      <ul>
        <li>
          <strong>Persistence:</strong>
          <ul>
            <li>Redis can write data to disk at configurable intervals (default: every 1 second).</li>
            <li>On restart after a crash, Redis reloads data from disk but may lose recent changes.</li>
          </ul>
        </li>
        <li>
          <strong>Replication:</strong>
          <ul>
            <li>Common deployment involves a primary (master) and one or more replicas (secondaries).</li>
            <li>Replicas sync from the primary’s append-only log.</li>
            <li>If a replica falls behind, it can fully resynchronize from the primary.</li>
          </ul>
        </li>
      </ul>

      <h3>Scaling and Clustering</h3>
      <ul>
        <li>
          <strong>Read Scaling:</strong>
          Multiple replicas can be added to scale read throughput.
        </li>
        <li>
          <strong>Write Scaling (Sharding):</strong>
          <ul>
            <li>Redis clusters use a hash slot mechanism (typically 16,384 slots).</li>
            <li>Each key is hashed to a slot, and each slot is assigned to a node.</li>
            <li>Clients should be aware of the cluster topology to route requests efficiently.</li>
            <li>Hot key issues (where one key receives disproportionate traffic) can be mitigated by appending random numbers or otherwise distributing keys.</li>
          </ul>
        </li>
      </ul>

      <h2>4. Common Redis Use Cases in System Design</h2>
      <h3>A. Caching</h3>
      <ul>
        <li>
          <strong>Pattern:</strong>
          Service checks Redis cache for data before querying the database. If not found, fetch from DB, store in Redis, and return to client.
        </li>
        <li>
          <strong>Key Concerns:</strong>
          <ul>
            <li><strong>Hot Key Problem:</strong> Distribute load by modifying keys (e.g., appending random values).</li>
            <li><strong>Expiration Policy:</strong>
              <ul>
                <li>Use <code>EXPIRE</code> to set TTL on cache entries.</li>
                <li>Optionally configure Redis for Least Recently Used (LRU) eviction when memory is full.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <h3>B. Rate Limiting</h3>
      <ul>
        <li>
          <strong>Pattern:</strong>
          Use <code>INCR</code> to atomically increment a counter for a user or API key. If the counter exceeds a threshold, block further requests. Set an expiry on the counter to reset after a time window.
        </li>
        <li>
          <strong>Limitations:</strong>
          <ul>
            <li>Under high load, fairness is not guaranteed.</li>
            <li>More advanced rate limiting (e.g., sliding windows, fairness) may require additional logic.</li>
          </ul>
        </li>
      </ul>

      <h3>C. Streams and Job Queues</h3>
      <ul>
        <li>
          <strong>Streams:</strong>
          Append-only log structure with ordered entries (IDs often based on timestamps). Supports consumer groups, which track processing progress. Workers claim items from the stream; if a worker fails, items can be reassigned.
        </li>
        <li>
          <strong>Guarantees:</strong>
          <ul>
            <li>At-least-once delivery (not exactly-once).</li>
            <li>Heartbeating is used for fault detection, but network partitions can lead to duplicate processing.</li>
          </ul>
        </li>
      </ul>

      <h3>D. Sorted Sets (Leaderboards)</h3>
      <ul>
        <li>
          <strong>Pattern:</strong>
          Store items (e.g., tweets) with a score (e.g., like count) in a sorted set. Use commands like <code>ZADD</code> to insert/update, and <code>ZRANGE</code> to retrieve top N items. Efficient for small to moderate-sized leaderboards.
        </li>
        <li>
          <strong>Scaling:</strong>
          For very large datasets, partition sorted sets by key (e.g., by keyword or hash) and aggregate results from multiple shards.
        </li>
      </ul>

      <h3>E. Geospatial Indexes</h3>
      <ul>
        <li>
          <strong>Pattern:</strong>
          Store items with longitude and latitude. Use <code>GEOADD</code> to insert, <code>GEOSEARCH</code> to query by radius. Internally, coordinates are geohashed and stored in a sorted set.
        </li>
        <li>
          <strong>Considerations:</strong>
          <ul>
            <li>If items rarely move, a static in-memory list may be more efficient.</li>
            <li>The geospatial index is per key (single node); sharding may be needed for very large datasets.</li>
          </ul>
        </li>
      </ul>

      <h3>F. Pub/Sub (Publish/Subscribe)</h3>
      <ul>
        <li>
          <strong>Pattern:</strong>
          Servers subscribe to topics (e.g., user IDs). Messages published to a topic are delivered to all subscribers.
        </li>
        <li>
          <strong>Use Case:</strong>
          Useful for real-time messaging (e.g., chat rooms) where users may connect to different servers.
        </li>
        <li>
          <strong>Limitations:</strong>
          <ul>
            <li>At-most-once delivery (no guarantee of message receipt).</li>
            <li>Not suitable for critical message delivery without additional reliability mechanisms.</li>
          </ul>
        </li>
      </ul>

      <h2>5. System Design Considerations and Pitfalls</h2>
      <ul>
        <li>
          <strong>Key Design Decisions:</strong>
          <ul>
            <li>How to shard keys for scalability.</li>
            <li>How to handle hot keys and uneven traffic distribution.</li>
            <li>Choosing appropriate expiration and eviction policies.</li>
            <li>Handling failures and ensuring data durability (e.g., using Redis forks like MemoryDB for higher reliability).</li>
            <li>Understanding delivery guarantees (e.g., at-least-once for streams, at-most-once for pub/sub).</li>
          </ul>
        </li>
        <li>
          <strong>Scaling Strategies:</strong>
          <ul>
            <li>Partition data by keyspace.</li>
            <li>Use client-side logic to distribute load.</li>
            <li>Aggregate results from multiple shards when needed.</li>
          </ul>
        </li>
        <li>
          <strong>Reliability:</strong>
          <ul>
            <li>Consider replication and persistence settings.</li>
            <li>Plan for failover and recovery scenarios.</li>
          </ul>
        </li>
      </ul>

      <h2>6. Conclusion</h2>
      <p>
        Redis is a powerful, flexible tool for a wide range of system design problems, including caching, rate limiting, job queues, leaderboards, geospatial indexing, and pub/sub messaging. Its simplicity and speed make it a popular choice, but understanding its operational model and limitations is crucial for effective use in production systems.
      </p>
      <blockquote>
        “If you understand [Redis internals], then you can reason through some of the issues that you might expect in production.” – Stefan
      </blockquote>

      <p>
        <strong>Further Reading:</strong><br>
        Refer to the deep dive write-up linked in the session description for additional details and examples.
      </p>

      <div class="reference">
        <strong>Reference:</strong><br>
        <a href="https://www.youtube.com/watch?v=fmT5nlEkl3U&t=308s" target="_blank">
          Redis Deep Dive w/ a Ex-Meta Senior Manager (YouTube)
        </a>
      </div>
    </div>
  </section>
  <div class="More reads">
    <strong>More reads:</strong><br>
    <a href="https://ravisystemdesign.substack.com/p/interview-prep-designing-a-distributed" target="_blank">
      Proper System design
    </a>
  </div>


</main>
</body>
</html>

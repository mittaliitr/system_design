<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Distributed Caching: Cleaned Full Transcript</title>
  <style>
    body {
        font-family: 'Segoe UI', Arial, sans-serif;
        background: #f8f9fa;
        color: #23272f;
        margin: 0;
        padding: 0 0 3em 0;
    }
    main {
        max-width: 900px;
        margin: 2em auto;
        background: #fff;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.07);
        padding: 2em 2.5em;
    }
    h1, h2 {
        color: #1a4d7a;
        margin-top: 1.5em;
    }
    h1 {
        text-align: center;
        margin-bottom: 0.5em;
    }
    section {
        margin-bottom: 2.5em;
    }
    ul, ol {
        margin-left: 1.5em;
    }
    .quote {
        color: #555;
        background: #f1f3f6;
        border-left: 4px solid #a2c2e2;
        padding: 0.8em 1.2em;
        margin: 1em 0;
        font-style: italic;
    }
    .subsection {
        margin-top: 1.2em;
        font-weight: bold;
        color: #2d5a88;
    }
    .table-wrap {
        overflow-x: auto;
    }
    table {
        border-collapse: collapse;
        width: 100%;
        margin: 1em 0;
    }
    th, td {
        border: 1px solid #d0d7de;
        padding: 0.6em 0.9em;
        text-align: left;
    }
    th {
        background: #e6f0fa;
    }
    .timestamp {
        color: #999;
        font-size: 0.95em;
    }
    .speaker {
        color: #1a4d7a;
        font-weight: bold;
    }
    .block {
        margin-bottom: 1.2em;
    }
  </style>
</head>
<body>
<main>
  <h1>Distributed Caching: Full Transcript (Cleaned)</h1>

  <section>
    <h2>Introduction to Distributed Caching</h2>
    <img src="/system_design/DistributedCaching/distributed_Caching.png" alt="Distributed Caching">

    <div class="block">
      <span class="timestamp">(00:00)</span> Welcome back. I've changed my camera angle, switched up my desk setup, and things are looking clean. We're getting close to the end of this systems design concepts series. Let's start talking about caching.
    </div>
    <div class="block">
      <span class="timestamp">(00:32)</span> If you remember from your operating systems class, here's what a CPU looks like: cores, layers of cache, memory, and finally disk. The point is, we have this hierarchy of cache that enables faster reads and writes, and shields some accesses to slower forms of data like memory and disk. In distributed systems, we're basically doing the same thing.
    </div>
    <div class="block">
      <span class="timestamp">(01:27)</span> Benefits of caching in distributed systems:
      <ul>
        <li>Reads and writes should be faster because you're using a faster form of storage, usually memory instead of disk.</li>
        <li>You might save a lot of network calls by not reaching out to the database every time.</li>
        <li>You can place the cache physically closer to the client, so packets travel less distance.</li>
        <li>Caching can reduce load on key components like a single database node if many clients are asking for the same data.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(02:56)</span> Drawbacks:
      <ul>
        <li>Cache misses are expensive and slow you down.</li>
        <li>Data consistency is complex. Different caches might have different values, leading to stale data.</li>
        <li>Complexity increases if you care about strong consistency.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(04:08)</span> What do we cache? Anything that's expensive to compute or load, like database results, computations done by application servers, or popular static content.
    </div>
    <div class="block">
      <span class="timestamp">(04:57)</span> Where do we store the cache?
      <ul>
        <li><b>Server-local caching:</b> Data is cached on the application servers themselves. This could be a database, message broker, application server, or coordination service.</li>
        <li>Example: If you keep checking who liked you on Tinder, it's more efficient to cache the result on the application server.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(06:21)</span> With multiple application servers, it's important to reach the same server every time for your specific cached data. Consistent hashing is used to maximize cache hits.
    </div>
    <div class="block">
      <span class="timestamp">(07:31)</span> Pros of server-local caching: fewer network calls, faster access. Cons: if the server goes down, the cache is lost; limited by the number of application servers.
    </div>
    <div class="block">
      <span class="timestamp">(08:03)</span> <b>Global caching layer:</b> A separate, scalable caching layer shared by all servers. Pros: can scale independently. Cons: cache is no longer local, more network calls, more moving parts.
    </div>
    <div class="block">
      <span class="timestamp">(09:30)</span> Caches improve latencies for reads and writes, use faster storage, and can be placed closer to the user. But cache misses are bad, and data consistency issues can arise. Next up: cache writes and eviction policies.
    </div>
  </section>

  <section>
    <h2>Distributed Cache Write Strategies</h2>
    <img src="/system_design/DistributedCaching/cache_Write.jpg" alt="Distributed cache write">

    <div class="block">
      <span class="timestamp">(00:00)</span> Quick recap: caching can make reads faster, sometimes writes too. Caching can act as a wall between the database and users, reducing load. But cache misses are expensive, and data consistency can be tough.
    </div>
    <div class="block">
      <span class="timestamp">(01:59)</span> Three ways to handle writes:
      <ol>
        <li><b>Write-Around Cache:</b> Write directly to the database, bypassing the cache. The cache is updated on the next read (either after cache expiry or manual invalidation). Pros: simple, database is the source of truth. Cons: cache misses after writes, potential for stale reads until cache is refreshed.</li>
        <li><b>Write-Through Cache:</b> Write to both the cache and the database at the same time. Ensures cache and database are kept in sync unless a failure occurs. Two-phase commit can be used for stronger consistency, but it's slow. Pros: consistent data. Cons: slower writes, complexity.</li>
        <li><b>Write-Back Cache:</b> Write to the cache first, then asynchronously write to the database (possibly in batches). Very fast writes, but risk of data loss if the cache fails before data is persisted. Consistency can be improved with distributed locks, but adds complexity and latency. Pros: very fast writes. Cons: risk of data loss, potential for stale reads, added complexity.</li>
      </ol>
    </div>
    <div class="block">
      <span class="timestamp">(10:55)</span> No clear winner: each write strategy has different use cases and tradeoffs.
    </div>
  </section>

  <section>
    <h2>Cache Eviction Policies</h2>
    <img src="/system_design/DistributedCaching/chace_Eviction_policy.jpg" alt="Distributed eviction">

    <div class="block">
      <span class="timestamp">(00:00)</span> When you have too much data in the cache, you have to get rid of some of it. The eviction policy determines what to remove.
    </div>
    <div class="block">
      <span class="timestamp">(01:56)</span> Eviction policies:
      <ul>
        <li><b>FIFO (First-In, First-Out):</b> Oldest cached item is removed first. Simple, but may evict frequently accessed data.</li>
        <li><b>LRU (Least Recently Used):</b> Removes the item that hasn't been accessed for the longest time. Implemented with a hashmap and doubly-linked list for O(1) updates. Common in practice.</li>
        <li><b>LFU (Least Frequently Used):</b> Removes the item accessed the least number of times. More complex to implement, but can better retain "hot" data.</li>
        <li><b>Random:</b> Evicts a random item. Simple, minimal metadata, but can remove useful data.</li>
      </ul>
    </div>
    <div class="block">
      <span class="timestamp">(07:10)</span> There is no single right answer for choosing an eviction policy, but some are better than others (e.g., LRU is generally better than FIFO or random).
    </div>
  </section>
  <img src="/system_design/DistributedCaching/resis_memcached.jpg" alt=redis vs memcached>

  <section>
    <h2>Redis vs. Memcached (Detailed Comparison)</h2>

    <div class="block">
      <span class="timestamp">(00:00)</span> So, Redis and Memcached are both super popular in-memory caching solutions, but they’re actually pretty different once you get into the details. Let’s break it down.
    </div>

    <div class="block">
      <b>Core Purpose and Use Case</b>
      <ul>
        <li>Memcached is your classic, no-frills, high-speed cache. It’s a simple key-value store-just strings, no fancy data types. If you need to cache database query results, HTML fragments, or session tokens, Memcached is super lightweight and easy to set up. It’s like a RAM-powered sticky note for your app <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li>Redis is more of a Swiss Army knife. It’s a cache, but also a data structure server, message broker, and even a lightweight database if you want it to be. You get strings, but also lists, sets, sorted sets, hashes, bitmaps, hyperloglogs, geospatial indexes, and more. If you want to build leaderboards, session stores, real-time analytics, or anything with more complex data, Redis is your go-to <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Data Structures</b>
      <ul>
        <li><b>Memcached:</b> Strings only. Everything is a string, so if you want to cache an object, you have to serialize it yourself. No way to update a single field in a cached object-you have to replace the whole thing <span class="timestamp">(03:25)</span>[3][6][7].</li>
        <li><b>Redis:</b> Strings, lists, sets, sorted sets, hashes, bitmaps, hyperloglogs, geospatial data. You can update just one field in a hash, push to a list, increment a counter, or run set operations-all in-memory and super fast <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Persistence</b>
      <ul>
        <li><b>Memcached:</b> Purely in-memory. If the server restarts, all data is gone. No built-in way to persist data to disk <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li><b>Redis:</b> Optional persistence. You can snapshot data to disk at intervals (RDB), or log every write operation (AOF). If you want your cache to survive restarts or act as a lightweight database, Redis has you covered <span class="timestamp">(05:13)</span>[2][3][4][5][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Threading and Performance</b>
      <ul>
        <li><b>Memcached:</b> Multi-threaded. Can use all CPU cores, so it’s great for high-concurrency, high-throughput workloads. Handles lots of simultaneous requests very efficiently <span class="timestamp">(03:43)</span>[2][3][4][6][7].</li>
        <li><b>Redis:</b> Historically single-threaded (one command at a time), but highly optimized with event-driven, non-blocking I/O. Recent versions support multi-threaded I/O for reads. Still, for pure parallelism, Memcached has the edge <span class="timestamp">(05:13)</span>[2][3][4][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Scalability and Clustering</b>
      <ul>
        <li><b>Memcached:</b> Scales horizontally by adding more nodes. Uses consistent hashing for partitioning data across nodes. No built-in replication or clustering-if a node fails, its data is lost <span class="timestamp">(03:43)</span>[2][3][4][6][7].</li>
        <li><b>Redis:</b> Supports clustering, replication, and sharding out of the box. Redis Cluster uses a fixed number of slots (partitions) distributed across nodes, with automatic failover. Also supports replicas for high availability <span class="timestamp">(05:50)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Advanced Features</b>
      <ul>
        <li><b>Memcached:</b> Keeps it simple-just caching, no extra features. LRU eviction by default, predictable memory usage via slab allocation <span class="timestamp">(04:54)</span>[3][4][7].</li>
        <li><b>Redis:</b>
          <ul>
            <li>Transactions (MULTI/EXEC)</li>
            <li>Pub/Sub messaging for real-time feeds and chat</li>
            <li>Lua scripting for custom logic</li>
            <li>Geospatial queries</li>
            <li>Bitmaps and HyperLogLogs for analytics</li>
            <li>Snapshots and append-only file for durability</li>
          </ul>
          <span class="timestamp">(06:22)</span>[2][3][4][5][6][7].
        </li>
      </ul>
    </div>

    <div class="block">
      <b>Memory Management</b>
      <ul>
        <li><b>Memcached:</b> Allocates a fixed amount of memory up front, uses slab allocation to minimize fragmentation. Predictable, but if you run out of memory, old data is evicted <span class="timestamp">(03:43)</span>[3][4][7][8].</li>
        <li><b>Redis:</b> Uses jemalloc for dynamic allocation and has a built-in defragmentation tool. Can be configured with or without a memory limit; supports multiple eviction policies <span class="timestamp">(05:13)</span>[3][4][7][8].</li>
      </ul>
    </div>

    <div class="block">
      <b>Programming Language Support</b>
      <ul>
        <li>Both Redis and Memcached have open-source clients for nearly every language: Java, Python, PHP, C, C++, C#, JavaScript, Node.js, Ruby, Go, and more <span class="timestamp">(General)</span>[2][3][4][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Typical Use Cases</b>
      <ul>
        <li><b>Memcached:</b> Simple, high-speed cache for database query results, session tokens, HTML fragments, and other string data. Great for web apps that need to cache lots of small, frequently accessed items <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li><b>Redis:</b> Session stores, leaderboards, real-time analytics, queues, pub/sub systems, geospatial lookups, and any use case that benefits from advanced data types or persistence <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>

    <div class="block">
      <b>Summary Table</b>
      <div class="table-wrap">
        <table>
          <tr>
            <th>Feature</th>
            <th>Redis</th>
            <th>Memcached</th>
          </tr>
          <tr>
            <td>Data Types</td>
            <td>Strings, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, geospatial</td>
            <td>Strings only</td>
          </tr>
          <tr>
            <td>Persistence</td>
            <td>Optional (RDB snapshots, AOF logs)</td>
            <td>None (RAM only)</td>
          </tr>
          <tr>
            <td>Threading</td>
            <td>Single-threaded (multi-threaded I/O in new versions)</td>
            <td>Multi-threaded</td>
          </tr>
          <tr>
            <td>Clustering</td>
            <td>Built-in clustering, replication, failover</td>
            <td>Manual sharding, no built-in replication</td>
          </tr>
          <tr>
            <td>Eviction Policy</td>
            <td>Configurable (LRU, LFU, etc.)</td>
            <td>LRU by default</td>
          </tr>
          <tr>
            <td>Transactions</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Pub/Sub</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Lua Scripting</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Geospatial</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Memory Management</td>
            <td>jemalloc, dynamic, defragmentation</td>
            <td>Slab allocation, fixed</td>
          </tr>
          <tr>
            <td>Best For</td>
            <td>Complex data, persistence, advanced features</td>
            <td>Simple, high-throughput caching</td>
          </tr>
        </table>
      </div>
    </div>

    <div class="block">
      <b>Which Should You Use?</b>
      <ul>
        <li>If you just need a blazing-fast, distributed cache for simple key-value pairs, Memcached is lightweight, easy, and efficient <span class="timestamp">(03:25)</span>[3][4][7].</li>
        <li>If you want advanced data types, persistence, clustering, or features like pub/sub and scripting, Redis is the clear winner. Redis can do everything Memcached can-and a lot more <span class="timestamp">(05:13)</span>[2][3][4][5][6][7].</li>
      </ul>
    </div>
  </section>
  <!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Redis Deep Dive – Distributed Systems Focus</title>
    <style>
      body {
        font-family: 'Segoe UI', Arial, sans-serif;
        background: #fff;
        color: #999;
        max-width: 900px;
        margin: 0 auto;
        padding: 2em 1em;
        line-height: 1.7;
      }
      h1, h2, h3 {
        color: #b30000;
        border-bottom: 1px solid #eee;
        padding-bottom: 0.2em;
        margin-top: 2em;
      }
      .timestamp {
        color: #888;
        font-size: 0.95em;
        margin-right: 0.5em;
        font-family: monospace;
      }
      .section {
        margin-bottom: 2em;
      }
      p {
        margin-top: 0.7em;
        margin-bottom: 0.7em;
      }
      ul, ol {
        margin: 0.5em 0 1em 2em;
      }
      .note {
        background: #f4f4f7;
        border-left: 4px solid #b30000;
        padding: 0.7em 1em;
        margin: 1.2em 0;
        font-style: italic;
      }
      code {
        background: #f6f8fa;
        padding: 0.1em 0.3em;
        border-radius: 3px;
        font-size: 0.95em;
      }
      .subsection {
        margin-top: 1.5em;
        margin-bottom: 1em;
        font-weight: bold;
        color: #444;
      }
      table {
        border-collapse: collapse;
        margin: 1em 0;
        width: 100%;
      }
      th, td {
        border: 1px solid #ddd;
        padding: 0.5em 0.8em;
        text-align: left;
      }
      th {
        background: #f7eaea;
      }
      @media (max-width: 600px) {
        body {
          padding: 1em 0.3em;
        }
      }
    </style>
  </head>
  <body>
  <h1>Redis Deep Dive: Distributed Systems Edition</h1>
  <div class="note">
    <strong>Note:</strong> This transcript and guide is enhanced for distributed systems engineers and system designers. All key distributed system concepts, trade-offs, and best practices are included.
  </div>

  <h2>Introduction</h2>
  <div class="section">
    <span class="timestamp">(00:00)</span>
    Welcome! This deep dive explores Redis with a focus on distributed system design. Redis is a versatile, high-performance in-memory database, cache, and data structure server. Its simplicity and speed make it a common building block in modern distributed architectures.
  </div>

  <h2>Redis Architectures in Distributed Systems</h2>
  <div class="section">
    <span class="timestamp">(02:13)</span>
    Redis can be deployed in several ways, each with unique implications for scalability, availability, and consistency:
    <ul>
      <li><strong>Single Instance:</strong> Easiest to set up, but a single point of failure. Suitable for small-scale or non-critical caches.</li>
      <li><strong>Leader-Follower (Primary-Replica):</strong> Replication adds redundancy and enables read scaling. Failover is possible but may require orchestration.</li>
      <li><strong>Sentinel:</strong> Provides monitoring and automated failover for leader-follower setups. Sentinels coordinate to promote replicas if the primary fails.</li>
      <li><strong>Cluster:</strong> Enables horizontal scaling via sharding. Data is partitioned across multiple nodes (shards), each with its own replicas for high availability.</li>
    </ul>
    <p>
      <strong>Persistence Options:</strong> Redis supports RDB (snapshotting) and AOF (append-only file) for durability. In distributed setups, persistence helps with recovery after failures, but there may be a small window of data loss unless both are carefully configured[2].
    </p>
  </div>

  <h2>Sharding and Scaling</h2>
  <div class="section">
    <span class="timestamp">(07:01)</span>
    <div class="subsection">How Redis Cluster Sharding Works</div>
    <ul>
      <li>Redis Cluster divides the key space into 16,384 hash slots. Each node is responsible for a subset of slots.</li>
      <li>Clients compute the slot for a key and route requests to the correct node. If a request goes to the wrong node, Redis returns a MOVED response, and the client retries.</li>
      <li>Sharding enables Redis to scale horizontally, overcoming the RAM and CPU limits of a single machine[3][7][8].</li>
    </ul>
    <div class="subsection">Best Practices for Sharding</div>
    <ul>
      <li><strong>Consistent Hashing:</strong> Minimizes rebalancing when adding/removing nodes. Redis Cluster uses a fixed hash slot scheme, but consistent hashing is a general best practice[6].</li>
      <li><strong>Key Design:</strong> Avoid hot keys by distributing load evenly. For example, append a random suffix or shard by user ID.</li>
      <li><strong>Cross-slot Operations:</strong> Avoid multi-key operations across different slots, as these are not natively supported in Redis Cluster[6].</li>
    </ul>
    <div class="subsection">Scaling Reads and Writes</div>
    <ul>
      <li>Read scaling: Add more replicas to serve read-heavy workloads.</li>
      <li>Write scaling: Add more shards (primary nodes). Writes are distributed based on key slot.</li>
    </ul>
  </div>

  <h2>High Availability and Failover</h2>
  <div class="section">
    <span class="timestamp">(06:03)</span>
    <div class="subsection">Replication and Automatic Failover</div>
    <ul>
      <li>Each primary node has one or more replicas. If a primary fails, a replica is promoted automatically (by Sentinel or Cluster logic)[3][4][7][8].</li>
      <li>Cluster nodes monitor each other via a gossip protocol and can agree to trigger failover if a primary is unresponsive.</li>
      <li>Failover and client redirection happen in seconds, keeping the system available with minimal disruption[4][7].</li>
    </ul>
    <div class="subsection">CAP Theorem and Partition Tolerance</div>
    <ul>
      <li>Redis Cluster is designed for CP (Consistency and Partition Tolerance) in the face of network partitions: the minority partition becomes unavailable, but the majority remains consistent and available[5].</li>
      <li>During a partition, writes to the minority partition may be lost after recovery (eventual consistency for a short period)[5].</li>
    </ul>
    <div class="subsection">Best Practices for HA</div>
    <ul>
      <li>Use at least three primary nodes to avoid split-brain scenarios[6].</li>
      <li>Ensure replicas are placed on different physical hosts or availability zones.</li>
      <li>Monitor memory usage and configure persistence according to durability needs[6].</li>
    </ul>
  </div>

  <h2>Deployment and Operational Considerations</h2>
  <div class="section">
    <div class="subsection">Memory Management</div>
    <ul>
      <li>Redis is in-memory; ensure your dataset fits in RAM across all nodes[6][7].</li>
      <li>Eviction policies (e.g., LRU) are triggered when memory limits are reached.</li>
    </ul>
    <div class="subsection">Monitoring and Observability</div>
    <ul>
      <li>Use <code>INFO</code> command, Redis Exporter, and Prometheus for monitoring[6].</li>
      <li>Track metrics like memory usage, replication lag, and failover events.</li>
    </ul>
    <div class="subsection">Persistence Strategies</div>
    <ul>
      <li>RDB: Snapshotting at intervals; fast recovery but possible data loss between snapshots.</li>
      <li>AOF: Logs every write; more durable but can be slower.</li>
      <li>Use both for a balance of performance and durability[2].</li>
    </ul>
  </div>

  <h2>Redis Use Cases in Distributed Systems</h2>
  <div class="section">
    <div class="subsection">Caching</div>
    <ul>
      <li>Offload frequent reads from primary databases.</li>
      <li>Distribute cache keys to avoid hot spots.</li>
      <li>Configure TTLs and eviction policies for consistency and memory control.</li>
    </ul>
    <div class="subsection">Rate Limiting</div>
    <ul>
      <li>Atomic <code>INCR</code> commands ensure accurate limits across distributed service instances.</li>
      <li>Set expirations to reset counters automatically.</li>
      <li>For fairness and resilience, consider distributed token bucket or leaky bucket algorithms.</li>
    </ul>
    <div class="subsection">Streams and Job Queues</div>
    <ul>
      <li>Streams provide distributed, fault-tolerant job queues with consumer groups.</li>
      <li>At-least-once delivery is standard; exactly-once requires extra logic.</li>
      <li>Worker heartbeats and claiming mechanisms help with failover and recovery.</li>
    </ul>
    <div class="subsection">Leaderboards and Sorted Sets</div>
    <ul>
      <li>Sorted sets (<code>ZSET</code>) are used for leaderboards, rankings, and time-series data.</li>
      <li>To scale, partition leaderboards by key or hash, then aggregate results as needed.</li>
    </ul>
    <div class="subsection">Geospatial Indexes</div>
    <ul>
      <li>Efficient for location-based queries in real time.</li>
      <li>Partition geospatial data by region or hash for massive scale.</li>
    </ul>
    <div class="subsection">Pub/Sub Messaging</div>
    <ul>
      <li>Fast, lightweight messaging for server-to-server or client-server communication.</li>
      <li>At-most-once delivery; not suitable for guaranteed delivery or persistence.</li>
      <li>Good for signaling and ephemeral notifications.</li>
    </ul>
  </div>

  <h2>Summary Table: Redis Distributed Architectures</h2>
  <table>
    <tr>
      <th>Architecture</th>
      <th>Scalability</th>
      <th>Availability</th>
      <th>Consistency</th>
      <th>Best For</th>
    </tr>
    <tr>
      <td>Single Instance</td>
      <td>Low</td>
      <td>Low</td>
      <td>Strong (if up)</td>
      <td>Development, small caches</td>
    </tr>
    <tr>
      <td>Leader-Follower</td>
      <td>Read scaling</td>
      <td>Medium (failover manual or Sentinel)</td>
      <td>Strong (eventual for replicas)</td>
      <td>Production caches, moderate scale</td>
    </tr>
    <tr>
      <td>Sentinel</td>
      <td>Read scaling</td>
      <td>High (automatic failover)</td>
      <td>Strong (eventual for replicas)</td>
      <td>HA setups without sharding</td>
    </tr>
    <tr>
      <td>Cluster</td>
      <td>High (sharding)</td>
      <td>High (auto failover, CP in CAP)</td>
      <td>Strong (per shard)</td>
      <td>Large-scale, distributed systems</td>
    </tr>
  </table>

  <h2>Conclusion</h2>
  <div class="section">
    Redis is a core building block for distributed systems, offering high performance, flexible data structures, and robust scaling and HA features. Proper deployment, key design, and operational practices are essential to leverage Redis effectively in large-scale, distributed environments[2][3][4][5][6][7][8].
  </div>
  </body>
  </html>


</main>
</body>
</html>

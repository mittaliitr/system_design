<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Partitioning of Key-Value Data</title>
</head>
<body>
<h1>Partitioning of Key-Value Data</h1>
<p>
  Say you have a large amount of data, and you want to partition it. How do you decide which records to store on which nodes?
</p>
<p>
  Our goal with partitioning is to spread the data and the query load evenly across nodes. If every node takes a fair share, then—in theory—10 nodes should be able to handle 10 times as much data and 10 times the read and write throughput of a single node (ignoring replication for now).
</p>
<p>
  If the partitioning is unfair, so that some partitions have more data or queries than others, we call it <strong>skewed</strong>. The presence of skew makes partitioning much less effective. In an extreme case, all the load could end up on one partition, so 9 out of 10 nodes are idle and your bottleneck is the single busy node. A partition with disproportionately high load is called a <strong>hot spot</strong>.
</p>
<p>
  The simplest approach for avoiding hot spots would be to assign records to nodes randomly. That would distribute the data quite evenly across the nodes, but it has a big disadvantage: when you’re trying to read a particular item, you have no way of knowing which node it is on, so you have to query all nodes in parallel.
</p>
<p>
  We can do better. Let’s assume for now that you have a simple key-value data model, in which you always access a record by its primary key. For example, in an old-fashioned paper encyclopedia, you look up an entry by its title; since all the entries are alphabetically sorted by title, you can quickly find the one you’re looking for.
</p>
</body>
</html>
